<html>

<head>
  <title>Express</title>
  <link rel="stylesheet" href="/stylesheets/style.css">
  <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>
</head>

<body>
  <video id="video" autoplay width="320" height="240"></video>
  <canvas id="rcanvas" width="320" height="240"></canvas>
  <canvas id="vcanvas" width="320" height="240"></canvas>
  <canvas id="ccanvas" width="320" height="240" style='display:none'></canvas>
  <br>
  <button onclick="start()">撮影開始</button>
  <button onclick="registerFace()">登録</button>
  <button onclick="verify()">照合</button>
  <br><br>
  圧縮後の画像サイズ:
  <select id="sselect">
    <option value="none">圧縮なし</option>
    <option value="640x480">640x480</option>
    <option value="480x360">480x360</option>
    <option value="320x240">320x240</option>
    <option value="240x180">240x180</option>
    <option value="160x120">160x120</option>
  </select>
  &nbsp;&nbsp;圧縮率:
  <input id="ctext" type="text" value="1.0">
  &nbsp;&nbsp;グレースケール化:
  <input id="gcheckbox" type="checkbox" value="grayscale">
  <br><br>
  <textarea id="msgbox" rows=5 cols=80></textarea>
  <br><br>
  <a href="/logout">ログアウト</a>
  <button onclick="detect()">detect</button>
</body>

<script type='module'>
  import * as facelib from './facelib.js';
  window.facelib = {
    ...facelib,
  };
</script>
<script>
  const video = document.getElementById('video');
  const rcanvas = document.getElementById('rcanvas');
  const vcanvas = document.getElementById('vcanvas');
  const ccanvas = document.getElementById('ccanvas');
  const sselect = document.getElementById('sselect');
  const ctext = document.getElementById('ctext');
  const gcheckbox = document.getElementById('gcheckbox');
  const msgbox = document.getElementById('msgbox');

  let stream;
  let streamSettings;
  let track;
  let ic;
  let blob;
  const params = {
    type: '',
    width: 0,
    height: 0
  };
  let doCompress = false;

  async function start() {
    try {
      const constraints = {
        audio: false,
        video: true
      };
      stream = await navigator.mediaDevices.getUserMedia(constraints);
      track = stream.getVideoTracks()[0];
      streamSettings = track.getSettings();
      console.log(streamSettings);
      ic = new ImageCapture(track);
      icc = await ic.getPhotoCapabilities();
      console.log(icc);
      video.srcObject = stream;
　　} catch(err) {
      console.log('start error');
　　}
  }

  async function capture() {
    try {
      blob = await ic.takePhoto();
      console.log(blob);
      params.type = blob.type;
      params.width = streamSettings.width;
      params.height = streamSettings.height;
    } catch(err) {
      console.log('capture error');
    }
  }

  async function drawImage(blob,canvas){
    const bitmap = await createImageBitmap(blob);
    const ctx = canvas.getContext("2d");
    if (gcheckbox.checked) {
      ctx.filter = 'grayscale(1)';
    } else {
      ctx.filter = 'none';
    }
    ctx.drawImage(bitmap, 0, 0, canvas.width, canvas.height);
  }

  async function compress() {
    await drawImage(blob, ccanvas);
    blob = await new Promise(resolve => {
      ccanvas.toBlob(b => {
        resolve(b);
      }, 'image/jpeg', Number(ctext.value));
    });
    console.log(blob);
    params.type = blob.type;
    params.width = ccanvas.width;
    params.height = ccanvas.height;
  }

  function setCompress(w, h) {
    doCompress = true;
    ccanvas.width = w;
    ccanvas.height = h;
  }

  sselect.onchange = function() {
    switch(this.value){
      case 'none':
        doCompress = false;
        return;
      case '640x480':
        setCompress(640,480);
        break;
      case '480x360':
        setCompress(480,360);
        break;
      case '320x240':
        setCompress(320, 240);
        break;
      case '240x180':
        setCompress(240, 180);
        break;
      case '160x120':
        setCompress(160, 120);
        break;
    }
  }

  //
  // API common
  //
  async function blob2base64(blob) {
    const ab = await blob.arrayBuffer();
    const uia = new Uint8Array(ab);
    const str = uia.reduce((data, byte) => {
      return data + String.fromCharCode(byte);
    }, '')
    return btoa(str);
  }

  async function postWithImage1(url, params, image) {
    params.image = await blob2base64(image);
    console.log(params);
    return await axios.post(url, params);
  }

  async function postWithImage2(url, params, image) {
    const form = new FormData();
    form.append('params', JSON.stringify(params));
    form.append('image', image);
    return await axios.post(url, form);
  }

  //
  // UI function
  //
  const msgs = [];

  function message(num, msg) {
    msgs[num] = msg;
    if (num === 0) {
      msgs[1] = msgs[2] = '';
    }
    msgbox.value = msgs.join('\n');
  }

  async function registerFace() {
    await capture();
    doCompress && await compress();
    await drawImage(blob,rcanvas);
    try {
      const res = await postWithImage1('/api/v1/faces', params, blob);
      console.log(res.data);
      message(0, `登録画像 type:${params.type} width:${params.width} height:${params.height} size:${blob.size}`);
    } catch(err) {
      console.log('registerFace error');
    }
  }

  async function verify() {
    await capture();
    doCompress && await compress();
    await drawImage(blob,vcanvas);
    try {
      const res = await postWithImage1('/api/v1/verify', params, blob);
      console.log(res.data);
      message(1, `照合画像 type:${params.type} width:${params.width} height:${params.height} size:${blob.size}`);
      const {isIdentical, confidence} = res.data;
      message(2, `照合結果 ${isIdentical} 信頼度:${confidence}`);
    } catch(err) {
      console.log('verify error');
    }
  }

  async function detect() {
    await capture();
    try {
      const res = await postWithImage1('/api/v1/detect', params, blob);
      console.log(res.data);
    } catch(err) {
      console.log('detect error');
    }
  }

</script>
</html>
